{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processed Dataset to be used as Input\n",
    "Morassi Sasso, Ariane (2020): Processed EVAL Dataset (30 secs window - min_max normalized - bfill). figshare. Dataset. https://doi.org/10.6084/m9.figshare.12649691\n",
    "`BFILL` means the window was selected before the start of the measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Graphs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Custom Packages\n",
    "import devicely\n",
    "\n",
    "# Signal Processing\n",
    "import scipy.stats as stats\n",
    "import scipy.signal as sig\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Custom Models\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the local minima that correspond to the starts of a cardiac cycle\n",
    "def find_cycle_starts(df, sample_rate=1000):\n",
    "    minima = sig.find_peaks(-df.values, distance=0.7*sample_rate)[0]\n",
    "    return minima\n",
    "\n",
    "# Returns the x values for those samples in the signal, that are closest to some given y value\n",
    "def find_xs_for_y(ys, y_val, sys_peak):\n",
    "    diffs = abs(ys - y_val)\n",
    "    x1 = diffs[:sys_peak].idxmin()\n",
    "    x2 = diffs[sys_peak:].idxmin()\n",
    "    return x1, x2\n",
    "\n",
    "# Takes a dataframe of calculated features and removes the outliers occurring due to inaccuracies in the signal\n",
    "def clean_window_features_of_outliers(df):\n",
    "    quant = df.quantile(0.8)\n",
    "    for col in df.columns:\n",
    "        if col.find('ts') == -1:\n",
    "            df = df[df[col] < quant[col]*2]\n",
    "    return df\n",
    "\n",
    "def find_clean_cycles_with_template(signal, verbose=False):\n",
    "    initial_cycle_starts = find_cycle_starts(signal)\n",
    "    if len(initial_cycle_starts) <= 1:\n",
    "        return []\n",
    "    template_length = math.floor(np.median(np.diff(initial_cycle_starts)))\n",
    "    cycle_starts = initial_cycle_starts[:-1]\n",
    "    while cycle_starts[-1] + template_length > len(signal):\n",
    "        cycle_starts = cycle_starts[:-1]\n",
    "    template = []\n",
    "    for i in range(template_length):\n",
    "        template.append(np.mean(signal[cycle_starts + i]))\n",
    "    \n",
    "    corr_coef = []\n",
    "    for cycle_start in cycle_starts:\n",
    "        corr_coef.append(np.corrcoef(template, signal[cycle_start:cycle_start+template_length])[0,1])\n",
    "\n",
    "    valid_indices = np.argwhere(np.array(corr_coef) >= 0.8)\n",
    "    if (len(valid_indices) > len(cycle_starts) / 2) and len(valid_indices) > 1:\n",
    "        cycle_starts = cycle_starts[np.squeeze(valid_indices)]\n",
    "        template2 = []\n",
    "        for i in range(template_length):\n",
    "            template2.append(np.mean(signal[cycle_starts + i]))\n",
    "        template = template2\n",
    "        \n",
    "    if verbose:\n",
    "        print('Cycle Template')\n",
    "        plot = plt.plot(template)\n",
    "        plt.show()\n",
    "        \n",
    "    # Check correlation of cycles with template\n",
    "    # SQI1: Pearson Correlation\n",
    "    sqi1_corr = []\n",
    "    for cycle_start in cycle_starts:\n",
    "        corr, _ = stats.pearsonr(template, signal[cycle_start:cycle_start+template_length])\n",
    "        sqi1_corr.append(corr)\n",
    "        \n",
    "    # SQI2: Pearson Correlation between the cycle, re-sampled to match the template length, \n",
    "    # and the template itself\n",
    "    sqi2_corr = []\n",
    "    for cycle_start in cycle_starts:\n",
    "        cycle_end = initial_cycle_starts[np.squeeze(np.argwhere(initial_cycle_starts==cycle_start)) + 1] \n",
    "        corr, _ = stats.pearsonr(template, sig.resample(signal[cycle_start:cycle_end], template_length))\n",
    "        sqi2_corr.append(corr)\n",
    "        \n",
    "    # Filter for correlation >= 0.8\n",
    "    corrs = np.array([sqi1_corr, sqi2_corr]).transpose()\n",
    "    cycle_starts = cycle_starts[np.all(corrs >= 0.8, axis=1)]\n",
    "    \n",
    "    if verbose:\n",
    "        print('Detected Valid Cycles')\n",
    "        fig = plt.figure(figsize=(12, 10), dpi=300)\n",
    "        #plt.xlabel('Samples', fontsize=24)\n",
    "        #plt.ylabel('Normalized Magnitude', fontsize=24)\n",
    "        plt.axis('off')\n",
    "        for cycle_start in cycle_starts:\n",
    "            plt.rcParams.update({'font.size': 16})\n",
    "            plt.plot(signal[cycle_start:cycle_start+template_length].to_numpy())\n",
    "        \n",
    "        # Save Valid Cycles\n",
    "        with open('../../config.json') as f:\n",
    "            config = json.load(f)\n",
    "        today = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "        figure_path = config['figures']\n",
    "    \n",
    "        millis = int(round(time.time() * 1000))\n",
    "        valid_cycles = os.path.join(figure_path, today, 'valid_cycles_eval')\n",
    "        \n",
    "        if not os.path.exists(valid_cycles):\n",
    "            os.makedirs(valid_cycles)\n",
    "        fig.savefig(os.path.join(valid_cycles, str(millis)+'_valid_cycles_eval.svg'), \n",
    "                    transparent=True, format='svg')\n",
    "        \n",
    "    cycles = []\n",
    "    for cycle_start in cycle_starts:\n",
    "        cycle_end = initial_cycle_starts[np.squeeze(np.argwhere(initial_cycle_starts==cycle_start)) + 1]\n",
    "        if (cycle_end - cycle_start) > template_length*1.2:\n",
    "            cycle_end = cycle_start + template_length\n",
    "        cycles.append((cycle_start, cycle_end))\n",
    "\n",
    "    return cycles\n",
    "    \n",
    "# Filter PPG Data\n",
    "def extract_features_for_cycle(window_df, signal, verbose=False):\n",
    "    cur_index = window_df.index.max() + 1\n",
    "    if np.isnan(cur_index):\n",
    "        cur_index = 0\n",
    "    signal.index = pd.to_datetime(signal.index, unit='ms')\n",
    "    signal = signal.interpolate(method='time')\n",
    "    signal = signal - signal.min()\n",
    "    max_amplitude = signal.max()\n",
    "    \n",
    "    peaks = sig.find_peaks(signal.values)[0]\n",
    "    sys_peak_ts = signal.index[peaks[0]]\n",
    "    \n",
    "    if verbose:\n",
    "        plt.figure()\n",
    "        plt.xlim((signal.index.min(), signal.index.max()))\n",
    "        plt.scatter(signal.index[peaks], signal[peaks])\n",
    "        plt.plot(signal.index, signal.values)\n",
    "    # Features\n",
    "    window_df = window_df.append(pd.DataFrame({'start_ts': signal.index.min(),\n",
    "                                               'sys_peak_ts': sys_peak_ts,\n",
    "                                               'T_S': (sys_peak_ts - signal.index.min()).total_seconds(),\n",
    "                                               'T_D': (signal.index.max() - sys_peak_ts).total_seconds()\n",
    "                                              }, index=[cur_index]), sort=False)\n",
    "    for p in [10, 25, 33, 50, 66, 75]:\n",
    "        p_ampl = p / 100 * max_amplitude\n",
    "        x1, x2 = find_xs_for_y(signal, p_ampl, peaks[0])\n",
    "        if verbose:\n",
    "            plt.scatter([x1, x2], signal[[x1, x2]])\n",
    "        window_df.loc[cur_index, 'DW_'+str(p)] = (x2 - sys_peak_ts).total_seconds()\n",
    "        window_df.loc[cur_index, 'DW_SW_sum_'+str(p)] = (x2 - x1).total_seconds()\n",
    "        window_df.loc[cur_index, 'DW_SW_ratio_'+str(p)] = (x2 - sys_peak_ts) / (sys_peak_ts - x1)\n",
    "    if verbose:\n",
    "        plt.show()\n",
    "    return window_df\n",
    "    \n",
    "def extract_features_for_window(df, verbose=False):\n",
    "    cycles = find_clean_cycles_with_template(df['bvp_filtered'], verbose=verbose)\n",
    "    if len(cycles) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    window_features = pd.DataFrame()\n",
    "    cur_index = 0\n",
    "    for i in range(len(cycles)):\n",
    "        window_features = extract_features_for_cycle(window_features, df['bvp_filtered'].iloc[cycles[i][0]:cycles[i][1]], verbose=verbose)\n",
    "        if i > 0:\n",
    "            window_features.loc[cur_index-1, 'CP'] = (window_features.loc[cur_index, 'sys_peak_ts'] - window_features.loc[cur_index-1, 'sys_peak_ts']).total_seconds()\n",
    "        cur_index = cur_index + 1\n",
    "    if verbose:\n",
    "        print('Cycle Features within Window:')\n",
    "        print(window_features)\n",
    "    window_features = clean_window_features_of_outliers(window_features)\n",
    "    return window_features\n",
    "\n",
    "def apply_filter(df, filter_type='cheby', fs=1000):\n",
    "    # The eval dataset was already normalized\n",
    "    if len(df['bvp']) <= 27:\n",
    "        df['bvp_filtered'] = df['bvp']\n",
    "        return df['bvp_filtered']\n",
    "    elif filter_type == 'cheby':\n",
    "        sos = sig.cheby2(4, 20, [0.5, 8], btype='bandpass', fs=fs, output='sos')\n",
    "        df['bvp_filtered'] = sig.sosfiltfilt(sos, df['bvp'])\n",
    "    elif filter_type == 'butter':\n",
    "        sos = sig.butter(4, [0.5, 8], btype='bandpass', fs=fs, output='sos')\n",
    "        df['bvp_filtered'] = sig.sosfiltfilt(sos, df['bvp'])\n",
    "    return df\n",
    "\n",
    "def extract_features_for_signal(signal, time, filter_type, verbose=False):\n",
    "    new_rows = pd.DataFrame()\n",
    "        \n",
    "    # Path for the json (for the image representation)\n",
    "    eval_dataset = os.path.join('..','..','datasets','eval')\n",
    "    if not os.path.exists(eval_dataset):\n",
    "        os.makedirs(eval_dataset)\n",
    "        \n",
    "    for index, row in signal.iterrows():\n",
    "        print(\"From:\", index)\n",
    "        df = pd.Series(row['ppg'][:time])*(-1)\n",
    "        window_df = pd.DataFrame.from_dict(df).rename(columns={0: 'bvp'})\n",
    "        \n",
    "        if verbose:\n",
    "            fig = plt.figure(figsize=(12, 10))\n",
    "            plt.plot(df)\n",
    "            plt.show()\n",
    "            fig = plt.figure(figsize=(12, 10))\n",
    "            plt.plot(window_df['bvp'])\n",
    "            plt.show()    \n",
    "        \n",
    "        window_df = apply_filter(window_df, filter_type=filter_type, fs=1000)\n",
    "        \n",
    "        # Generate new json (for the image representation)\n",
    "        row['ppg'] = window_df['bvp_filtered'].tolist()\n",
    "        new_rows = new_rows.append(row)\n",
    "        \n",
    "        if verbose: print(\"PPG shape\", len(row['ppg'][:time]))\n",
    "        if verbose:\n",
    "            fig = plt.figure(figsize=(12, 10))\n",
    "            plt.plot(df)\n",
    "            plt.show()\n",
    "            fig = plt.figure(figsize=(12, 10))\n",
    "            plt.plot(window_df['bvp_filtered'])\n",
    "            plt.show()    \n",
    "        window_features = extract_features_for_window(window_df, verbose)\n",
    "        for col in window_features.columns:\n",
    "            if col.find('ts') == -1:\n",
    "                signal.loc[index, col+'_mean'] = window_features[col].mean()\n",
    "                signal.loc[index, col+'_var'] = window_features[col].var()\n",
    "\n",
    "    signal.dropna(inplace=True, how='any')\n",
    "\n",
    "    print(new_rows.shape)\n",
    "    # Save the json (for the image representation)\n",
    "    new_rows.rename(columns={'subject':'patientid', 'SYS(mmHg)':'sbp', 'DIA(mmHg)':'dbp'}, inplace = True)\n",
    "    json_eval = new_rows.to_json(orient='records')\n",
    "    json_eval_final = json.loads(json_eval)\n",
    "    file_name = os.path.join(eval_dataset, 'eval_ppg_snippets-'+str(round(time/1000))+'sec-'+filter_type+'.json')\n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write(json.dumps(json_eval_final))\n",
    "    \n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(csv=True, time_delta='15 seconds', time_delta_type = 'bfill', \n",
    "                    experiment_type='eval', motion_filter=False, special_filter='cheby', verbose=False):\n",
    "    \n",
    "    with open('../../config.json') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    today = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "    exp_base_path = config['eval']\n",
    "    figure_path = config['figures']\n",
    "    \n",
    "    if verbose:\n",
    "        print(exp_base_path)\n",
    "        print(figure_path)\n",
    "        print('\\n')\n",
    "\n",
    "    today = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "    eval_df = pd.read_json(os.path.join(exp_base_path, 'eval_ppg_snippets.json')).rename(\n",
    "        columns={'patientid':'subject','sbp':'SYS(mmHg)','dbp':'DIA(mmHg)'})\n",
    "    print(\"Eval shape: \", eval_df.shape)\n",
    "    \n",
    "    # Create features path if it does not exist\n",
    "    features_path = os.path.join('..', '..', 'features', 'eval', today, experiment_type.replace(' ',''), time_delta.replace(' ','')+'-'+time_delta_type+'-'+str(special_filter).lower(), 'motion-not-filtered')\n",
    "\n",
    "    if not os.path.exists(features_path):\n",
    "        os.makedirs(features_path)\n",
    "\n",
    "    print('Extracting Features...')\n",
    "    print('-----','\\n')\n",
    "    \n",
    "    time = int(time_delta.split()[0])*1000\n",
    "    print(\"Time window (ms): \", time)\n",
    "    features = extract_features_for_signal(eval_df, time=time, filter_type=special_filter, verbose=verbose)\n",
    "\n",
    "    if 'T_S_mean' not in features:\n",
    "        return 0\n",
    "\n",
    "    if verbose: print('Features: ', features.shape)\n",
    "        \n",
    "    features['time_delta'] = time_delta\n",
    "    features['time_delta_type'] = time_delta_type\n",
    "    features['experiment_type'] = experiment_type\n",
    "    features['motion_filter'] = motion_filter\n",
    "    features['special_filter'] = special_filter\n",
    "\n",
    "    if csv:\n",
    "        all_features_path = features_path+'/all_features_{}_{}.csv'.format(experiment_type.replace(' ',''), time_delta.replace(' ','')+'-'+time_delta_type+'-'+str(special_filter).lower())\n",
    "        all_features = features.drop(['ppg'], axis=1)\n",
    "        all_features.to_csv(all_features_path, index=False)\n",
    "    if verbose: print(all_features)\n",
    "    if verbose: print('-----','\\n')\n",
    "    \n",
    "    print('Amount of BP-Pairs: ', all_features.shape)\n",
    "    print('Features Extracted.')\n",
    "    print('-----','\\n')\n",
    "    \n",
    "    return all_features_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def drop_correlation(df, labels, threshold = 0.95, plotcorr = False):\n",
    "    corr = df.loc[:, ~df.columns.isin(labels)].corr()\n",
    "    if plotcorr: \n",
    "        f, ax = plt.subplots(figsize=(15, 15))\n",
    "        cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "        sns.heatmap(corr, cmap = cmap,\n",
    "                xticklabels=corr.columns.values,\n",
    "                yticklabels=corr.columns.values)\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr.abs().where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "    # Find features with correlation greater than threshold\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    print(\"Columns dropped: \", len(to_drop))\n",
    "    # Drop features \n",
    "    return(df.drop(columns = to_drop))\n",
    "\n",
    "def predict_bp_from_ppg(dataframe, predicted_variable = 'SBP', k = 1, correlation_threshold = 0.95, \n",
    "                        random_seed = 42, learning_rate = 0.01, n_estimators = 100, \n",
    "                        alpha = 1, l1_ratio = 0.5, random_state = 42, \n",
    "                        epochs = 50, batch_size = 5, n_jobs = -1, max_depth = 10, verbose = False):\n",
    "     \n",
    "    df = dataframe.rename(columns={\"SYS(mmHg)\": \"SBP\", \"DIA(mmHg)\": \"DBP\", 'subject': 'patientid'})\n",
    "    \n",
    "    # Dropping Null Values\n",
    "    df.drop(df.loc[(df['SBP'] == 0)|(df['DBP'] == 0)].index, inplace = True)\n",
    "    df = drop_correlation(df, ['SBP', 'DBP'], correlation_threshold, plotcorr = False)\n",
    "    print(\"New Dataframe Shape: \" + str(df.shape))\n",
    "    if verbose: print(df.shape)\n",
    "\n",
    "    features = df.shape[1]-3\n",
    "    print(\"Nr of features: \", features)\n",
    "    if verbose: print(\"Columns: \", df.columns)\n",
    "    patient_ids = np.unique(df['patientid'])\n",
    "\n",
    "    estimators_lr = []\n",
    "    estimators_lr.append(('standardize', StandardScaler()))\n",
    "    estimators_lr.append(('lr', ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=random_state)))\n",
    "    pipeline_lr = Pipeline(estimators_lr)\n",
    "\n",
    "    estimators_gbm = []\n",
    "    estimators_gbm.append(('standardize', StandardScaler()))\n",
    "    estimators_gbm.append(('gbm', GradientBoostingRegressor(learning_rate=learning_rate, n_estimators=n_estimators, random_state=random_seed)))\n",
    "    pipeline_gbm = Pipeline(estimators_gbm)\n",
    "    \n",
    "    estimators_lgbm = []\n",
    "    estimators_lgbm.append(('standardize', StandardScaler()))\n",
    "    estimators_lgbm.append(('lgbm', lgb.LGBMRegressor(learning_rate=learning_rate, n_estimators=n_estimators, random_state=random_seed, n_jobs=n_jobs)))\n",
    "    pipeline_lgbm = Pipeline(estimators_lgbm)\n",
    "    \n",
    "    estimators_rf = []\n",
    "    estimators_rf.append(('standardize', StandardScaler()))\n",
    "    estimators_rf.append(('rf', RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state, n_jobs=n_jobs)))\n",
    "    pipeline_rf = Pipeline(estimators_rf)\n",
    "\n",
    "    RMSE_LR = []\n",
    "    MAPE_LR = []\n",
    "    MAE_LR = []\n",
    "\n",
    "    RMSE_GBM = []\n",
    "    MAPE_GBM = []\n",
    "    MAE_GBM = []\n",
    "    \n",
    "    RMSE_DUMMY = []\n",
    "    MAPE_DUMMY = []\n",
    "    MAE_DUMMY = []\n",
    "    \n",
    "    RMSE_LGBM = []\n",
    "    MAPE_LGBM = []\n",
    "    MAE_LGBM = []\n",
    "    \n",
    "    RMSE_RF = []\n",
    "    MAPE_RF = []\n",
    "    MAE_RF = []\n",
    "\n",
    "    results = {}\n",
    "    i = 0\n",
    "    mean_train = 0\n",
    "    mean_test = 0\n",
    "    total = len(df.index)\n",
    "    subjects = len(df['patientid'].unique())\n",
    "    \n",
    "    if verbose: print(\"BPPairs: \", total)\n",
    "    if verbose: print(\"Subjects: \", subjects)\n",
    "    if verbose: print(\"\\n\")\n",
    "\n",
    "    while len(patient_ids) > 1:\n",
    "        i= i + 1 \n",
    "\n",
    "        # Random Seed\n",
    "        random.seed(random_seed)\n",
    "\n",
    "        patient_test_ids = random.choices(patient_ids, k = k)\n",
    "        patient_ids = [e for e in patient_ids if e not in patient_test_ids]\n",
    "        df_test = df.loc[df['patientid'].isin(patient_test_ids)].dropna()\n",
    "        df_train = df[~df['patientid'].isin(patient_test_ids)].dropna()\n",
    "        if verbose: print(\"Running fold\" + str(i))\n",
    "        if verbose: print(\"Train: \", df_train.shape)\n",
    "        mean_train += len(df_train.index)\n",
    "        if verbose: print(\"Test: \", df_test.shape)\n",
    "        if verbose: print(\"Total: \", len(df_test.index) + len(df_train.index))\n",
    "        mean_test += len(df_test.index)\n",
    "        if verbose: print(\"\\n\")\n",
    "\n",
    "        cols_dropped = ['patientid']\n",
    "\n",
    "        if predicted_variable == 'SBP':\n",
    "            cols_dropped.append('DBP')\n",
    "        elif predicted_variable == 'DBP':\n",
    "            cols_dropped.append('SBP')\n",
    "        df_train = df_train.drop(columns = cols_dropped)\n",
    "        df_test = df_test.drop(columns = cols_dropped)\n",
    "\n",
    "        #lr\n",
    "        pipeline_lr.fit(X = df_train.loc[:, df_train.columns != predicted_variable].values, \n",
    "                        y = df_train[predicted_variable].values)\n",
    "        predicted_labels = pipeline_lr.predict(df_test.loc[:, df_test.columns != predicted_variable].values)\n",
    "\n",
    "        RMSE_LR.append(np.sqrt(mean_squared_error(df_test[predicted_variable], predicted_labels)))  \n",
    "        MAPE_LR.append(mean_absolute_percentage_error(df_test[predicted_variable], predicted_labels))\n",
    "        MAE_LR.append(mean_absolute_error(df_test[predicted_variable], predicted_labels))\n",
    "\n",
    "        #gbm \n",
    "        pipeline_gbm.fit(X = df_train.loc[:, df_train.columns != predicted_variable].values, \n",
    "                         y = df_train[predicted_variable].values)\n",
    "        predicted_labels = pipeline_gbm.predict(df_test.loc[:, df_test.columns != predicted_variable].values)\n",
    "\n",
    "        RMSE_GBM.append(np.sqrt(mean_squared_error(df_test[predicted_variable], predicted_labels)))  \n",
    "        MAPE_GBM.append(mean_absolute_percentage_error(df_test[predicted_variable], predicted_labels))\n",
    "        MAE_GBM.append(mean_absolute_error(df_test[predicted_variable], predicted_labels))\n",
    "        \n",
    "        #lightgbm\n",
    "        pipeline_lgbm.fit(X = df_train.loc[:, df_train.columns != predicted_variable].values, y = df_train[predicted_variable].values)\n",
    "        predicted_labels = pipeline_lgbm.predict(df_test.loc[:, df_test.columns != predicted_variable].values)\n",
    "\n",
    "        RMSE_LGBM.append(np.sqrt(mean_squared_error(df_test[predicted_variable], predicted_labels)))  \n",
    "        MAPE_LGBM.append(mean_absolute_percentage_error(df_test[predicted_variable], predicted_labels))\n",
    "        MAE_LGBM.append(mean_absolute_error(df_test[predicted_variable], predicted_labels))\n",
    "        \n",
    "        #rf\n",
    "        pipeline_rf.fit(X = df_train.loc[:, df_train.columns != predicted_variable].values, y = df_train[predicted_variable].values)\n",
    "        predicted_labels = pipeline_rf.predict(df_test.loc[:, df_test.columns != predicted_variable].values)\n",
    "\n",
    "        RMSE_RF.append(np.sqrt(mean_squared_error(df_test[predicted_variable], predicted_labels)))  \n",
    "        MAPE_RF.append(mean_absolute_percentage_error(df_test[predicted_variable], predicted_labels))\n",
    "        MAE_RF.append(mean_absolute_error(df_test[predicted_variable], predicted_labels))\n",
    "        \n",
    "        #dummy_mean\n",
    "        dummy_mean = DummyRegressor(strategy='mean')\n",
    "        dummy_mean.fit(X = df_train.loc[:, df_train.columns != predicted_variable].values, \n",
    "                         y = df_train[predicted_variable].values)\n",
    "        predicted_labels = dummy_mean.predict(df_test.loc[:, df_test.columns != predicted_variable].values)\n",
    "\n",
    "        RMSE_DUMMY.append(np.sqrt(mean_squared_error(df_test[predicted_variable], predicted_labels)))  \n",
    "        MAPE_DUMMY.append(mean_absolute_percentage_error(df_test[predicted_variable], predicted_labels))\n",
    "        MAE_DUMMY.append(mean_absolute_error(df_test[predicted_variable], predicted_labels))\n",
    "    \n",
    "    # General Info\n",
    "    results['subjects'] = subjects\n",
    "    results['bp_pairs'] = total\n",
    "    results['folders'] = i\n",
    "    results['mean_train_size'] = round(mean_train/i)\n",
    "    results['mean_test_size'] = round(mean_test/i)\n",
    "    \n",
    "    # Mean LR\n",
    "    results['RMSE_LR_MEAN'] = np.mean(np.array(RMSE_LR))\n",
    "    results['MAPE_LR_MEAN'] = np.mean(np.array(MAPE_LR))\n",
    "    results['MAE_LR_MEAN'] = np.mean(np.array(MAE_LR))\n",
    "            \n",
    "    # STD LR\n",
    "    results['RMSE_LR_STD'] = np.std(np.array(RMSE_LR))\n",
    "    results['MAPE_LR_STD'] = np.std(np.array(MAPE_LR))\n",
    "    results['MAE_LR_STD'] = np.std(np.array(MAE_LR))\n",
    "\n",
    "    # Mean GBM\n",
    "    results['RMSE_GBM_MEAN'] = np.mean(np.array(RMSE_GBM))\n",
    "    results['MAPE_GBM_MEAN'] = np.mean(np.array(MAPE_GBM))\n",
    "    results['MAE_GBM_MEAN'] = np.mean(np.array(MAE_GBM))\n",
    "    \n",
    "    # Std GBM\n",
    "    results['RMSE_GBM_STD'] = np.std(np.array(RMSE_GBM))\n",
    "    results['MAPE_GBM_STD'] = np.std(np.array(MAPE_GBM))\n",
    "    results['MAE_GBM_STD'] = np.std(np.array(MAE_GBM))\n",
    "    \n",
    "    # Mean LGBM\n",
    "    results['RMSE_LGBM_MEAN'] = np.mean(np.array(RMSE_LGBM))\n",
    "    results['MAPE_LGBM_MEAN'] = np.mean(np.array(MAPE_LGBM))\n",
    "    results['MAE_LGBM_MEAN'] = np.mean(np.array(MAE_LGBM))\n",
    "    \n",
    "    # Std LGBM\n",
    "    results['RMSE_LGBM_STD'] = np.std(np.array(RMSE_LGBM))\n",
    "    results['MAPE_LGBM_STD'] = np.std(np.array(MAPE_LGBM))\n",
    "    results['MAE_LGBM_STD'] = np.std(np.array(MAE_LGBM))\n",
    "    \n",
    "    # Mean RF\n",
    "    results['RMSE_RF_MEAN'] = np.mean(np.array(RMSE_RF))\n",
    "    results['MAPE_RF_MEAN'] = np.mean(np.array(MAPE_RF))\n",
    "    results['MAE_RF_MEAN'] = np.mean(np.array(MAE_RF))\n",
    "    \n",
    "    # Std RF\n",
    "    results['RMSE_RF_STD'] = np.std(np.array(RMSE_RF))\n",
    "    results['MAPE_RF_STD'] = np.std(np.array(MAPE_RF))\n",
    "    results['MAE_RF_STD'] = np.std(np.array(MAE_RF))\n",
    "    \n",
    "    # Mean Dummy\n",
    "    results['RMSE_DUMMY_MEAN'] = np.mean(np.array(RMSE_DUMMY))\n",
    "    results['MAPE_DUMMY_MEAN'] = np.mean(np.array(MAPE_DUMMY))\n",
    "    results['MAE_DUMMY_MEAN'] = np.mean(np.array(MAE_DUMMY))\n",
    "    \n",
    "    # Std Dummy\n",
    "    results['RMSE_DUMMY_STD'] = np.std(np.array(RMSE_DUMMY))\n",
    "    results['MAPE_DUMMY_STD'] = np.std(np.array(MAPE_DUMMY))\n",
    "    results['MAE_DUMMY_STD'] = np.std(np.array(MAE_DUMMY))\n",
    "    \n",
    "    parameters = {\n",
    "                    'predicted_variable' : predicted_variable,\n",
    "                    'correlation_threshold' : correlation_threshold, \n",
    "                    'random_seed' :  random_seed,\n",
    "                    'learning_rate' : learning_rate, \n",
    "                    'n_estimators' : n_estimators, \n",
    "                    'alpha' : alpha, \n",
    "                    'l1_ratio' : l1_ratio,\n",
    "                    'random_state' : random_state, \n",
    "                    'k' : k, \n",
    "                    'features' : features, \n",
    "                    'epochs' : epochs, \n",
    "                    'batch_size' : batch_size,\n",
    "                    'max_depth' : max_depth,\n",
    "                    'n_jobs' : n_jobs,\n",
    "    }    \n",
    "    results.update(parameters)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JAIME 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_parameters = {\n",
    "                        'csv' : True,\n",
    "                        'time_delta' : '15 seconds',\n",
    "                        'time_delta_type': 'bfill',       \n",
    "                        'experiment_type' : 'eval', \n",
    "                        'special_filter' : 'cheby',\n",
    "                        'verbose' : False\n",
    "                        }\n",
    "\n",
    "correlation_threshold = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = extract_features(csv=feature_parameters['csv'],\n",
    "                        time_delta=feature_parameters['time_delta'], \n",
    "                        time_delta_type=feature_parameters['time_delta_type'], \n",
    "                        experiment_type = feature_parameters['experiment_type'], \n",
    "                        special_filter = feature_parameters['special_filter'], \n",
    "                        verbose=feature_parameters['verbose'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicting for: \", path)\n",
    "df = pd.read_csv(path)\n",
    "print(df.shape)\n",
    "\n",
    "experiments = []    \n",
    "if not df.empty:\n",
    "        predicted_variables = ['SBP', 'DBP']\n",
    "        ks = [1, 2, 3]\n",
    "        \n",
    "        features = {\n",
    "                    'time_delta' : df['time_delta'].unique()[0],\n",
    "                    'time_delta_type' : df['time_delta_type'].unique()[0],\n",
    "                    'experiment_type' : df['experiment_type'].unique()[0], \n",
    "                    'motion_filter' : df['motion_filter'].unique()[0],\n",
    "                    'special_filter' : df['special_filter'].unique()[0]\n",
    "                    }\n",
    "        \n",
    "        df.drop(features.keys(), axis=1, inplace=True)\n",
    "        for variable in predicted_variables:\n",
    "            for k in ks:\n",
    "                results = predict_bp_from_ppg(df, predicted_variable = variable, \n",
    "                                              k = k, correlation_threshold = correlation_threshold)\n",
    "                results.update(features)\n",
    "                experiments.append(results)\n",
    "else:\n",
    "    (\"Dataframe was empty: \", path)\n",
    "all_experiments = pd.DataFrame.from_dict(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiments = all_experiments.replace({'motion_filter': {True : 'yes', False: 'no'}})\n",
    "all_experiments.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "all_experiments.to_csv('../../results/'+date+'_results_eval.csv', index=True, mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = '../../results/'+date+'_results_eval.csv'\n",
    "all_experiments = pd.read_csv(results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = all_experiments[['predicted_variable','experiment_type','MAE_GBM_MEAN','MAE_GBM_STD','MAPE_GBM_MEAN','RMSE_GBM_MEAN','special_filter','time_delta','time_delta_type','motion_filter','k']].sort_values(by=['predicted_variable','experiment_type','k','MAE_GBM_MEAN'])\n",
    "lgbm = all_experiments[['predicted_variable','experiment_type','MAE_LGBM_MEAN','MAE_LGBM_STD','MAPE_LGBM_MEAN','RMSE_LGBM_MEAN','special_filter','time_delta','time_delta_type','motion_filter','k']].sort_values(by=['predicted_variable','experiment_type','k','MAE_LGBM_MEAN'])\n",
    "lr = all_experiments[['predicted_variable','experiment_type','MAE_LR_MEAN','MAE_LR_STD','MAPE_LR_MEAN','RMSE_LR_MEAN','special_filter','time_delta','time_delta_type','motion_filter','k']].sort_values(by=['predicted_variable','experiment_type','k','MAE_LR_MEAN'])\n",
    "rf = all_experiments[['predicted_variable','experiment_type','MAE_RF_MEAN','MAE_RF_STD','MAPE_RF_MEAN','RMSE_RF_MEAN','special_filter','time_delta','time_delta_type','motion_filter','k']].sort_values(by=['predicted_variable','experiment_type','k','MAE_RF_MEAN'])\n",
    "d = all_experiments[['predicted_variable','experiment_type','MAE_DUMMY_MEAN','MAE_DUMMY_STD','MAPE_DUMMY_MEAN','RMSE_DUMMY_MEAN','special_filter','time_delta','time_delta_type','motion_filter','k']].sort_values(by=['predicted_variable','experiment_type','k','MAE_DUMMY_MEAN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.loc[(gbm['experiment_type'] == 'eval') & (gbm['predicted_variable'] == 'SBP') & (gbm['k'] == 1)].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbm.loc[(gbm['experiment_type'] == 'eval') & (gbm['predicted_variable'] == 'DBP') & (gbm['k'] == 1)].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.groupby(['predicted_variable','experiment_type']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.loc[(lr['experiment_type'] == 'eval') & (lr['predicted_variable'] == 'SBP') & (lr['k'] == 1)].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.loc[(lr['experiment_type'] == 'eval') & (lr['predicted_variable'] == 'DBP') & (lr['k'] == 1)].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.groupby(['predicted_variable','experiment_type']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm.loc[(lgbm['experiment_type'] == 'eval') & (lgbm['predicted_variable'] == 'SBP') & (lgbm['k'] == 1)].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm.loc[(lgbm['experiment_type'] == 'eval') & (lgbm['predicted_variable'] == 'DBP') & (lgbm['k'] == 1)].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.groupby(['predicted_variable','experiment_type']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.loc[(rf['experiment_type'] == 'eval') & (rf['predicted_variable'] == 'SBP') & (rf['k'] == 1)].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.loc[(rf['experiment_type'] == 'eval') & (rf['predicted_variable'] == 'DBP') & (rf['k'] == 1)].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.groupby(['predicted_variable','experiment_type']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DUMMY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.loc[(d['experiment_type'] == 'eval') & (d['predicted_variable'] == 'SBP')& (d['k'] == 1)].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.loc[(d['experiment_type'] == 'eval') & (d['predicted_variable'] == 'DBP') & (d['k'] == 1)].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.groupby(['predicted_variable','experiment_type']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best DBP & SBP JAIME 2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_min_eval_dbp = gbm.loc[(gbm['experiment_type'] == 'eval') & (gbm['predicted_variable'] == 'DBP') & (gbm['k'] == 1)].head(1)[['predicted_variable','experiment_type','k','MAE_GBM_MEAN','MAE_GBM_STD']]\n",
    "lgbm_min_eval_dbp = lgbm.loc[(lgbm['experiment_type'] == 'eval') & (lgbm['predicted_variable'] == 'DBP') & (lgbm['k'] == 1)].head(1)[['predicted_variable','experiment_type','k','MAE_LGBM_MEAN','MAE_LGBM_STD']]\n",
    "rf_min_eval_dbp = rf.loc[(rf['experiment_type'] == 'eval') & (rf['predicted_variable'] == 'DBP') & (rf['k'] == 1)].head(1)[['predicted_variable','experiment_type','k','MAE_RF_MEAN','MAE_RF_STD']]\n",
    "lr_min_eval_dbp = lr.loc[(lr['experiment_type'] == 'eval') & (lr['predicted_variable'] == 'DBP') & (lr['k'] == 1)].head(1)[['predicted_variable','experiment_type','k','MAE_LR_MEAN','MAE_LR_STD']]\n",
    "dummy_min_eval_dbp = d.loc[(d['experiment_type'] == 'eval') & (d['predicted_variable'] == 'DBP') & (d['k'] == 1)].head(1)[['predicted_variable','experiment_type','k','MAE_DUMMY_MEAN','MAE_DUMMY_STD']]\n",
    "\n",
    "min_eval_dbp = gbm_min_eval_dbp.set_index(['predicted_variable','experiment_type','k']).join(lgbm_min_eval_dbp.set_index(['predicted_variable','experiment_type','k']), on=['predicted_variable','experiment_type','k'])\n",
    "min_eval_dbp = min_eval_dbp.join(rf_min_eval_dbp.set_index(['predicted_variable','experiment_type','k']), on=['predicted_variable','experiment_type','k'])\n",
    "min_eval_dbp = min_eval_dbp.join(lr_min_eval_dbp.set_index(['predicted_variable','experiment_type','k']), on=['predicted_variable','experiment_type','k'])\n",
    "min_eval_dbp = min_eval_dbp.join(dummy_min_eval_dbp.set_index(['predicted_variable','experiment_type','k']), on=['predicted_variable','experiment_type','k'])\n",
    "display(min_eval_dbp)\n",
    "\n",
    "gbm_min_eval_sbp = gbm.loc[(gbm['experiment_type'] == 'eval') & (gbm['predicted_variable'] == 'SBP') & (gbm['k'] == 1)].head(1)[['predicted_variable','experiment_type','k','MAE_GBM_MEAN','MAE_GBM_STD']]\n",
    "lgbm_min_eval_sbp = lgbm.loc[(lgbm['experiment_type'] == 'eval') & (lgbm['predicted_variable'] == 'SBP') & (lgbm['k'] == 1)].head(1)[['predicted_variable','experiment_type','k','MAE_LGBM_MEAN','MAE_LGBM_STD']]\n",
    "rf_min_eval_sbp = rf.loc[(rf['experiment_type'] == 'eval') & (rf['predicted_variable'] == 'SBP') & (rf['k'] == 1)].head(1)[['predicted_variable','experiment_type','k','MAE_RF_MEAN','MAE_RF_STD']]\n",
    "lr_min_eval_sbp = lr.loc[(lr['experiment_type'] == 'eval') & (lr['predicted_variable'] == 'SBP') & (lr['k'] == 1)].head(1)[['predicted_variable','experiment_type','k','MAE_LR_MEAN','MAE_LR_STD']]\n",
    "dummy_min_eval_sbp = d.loc[(d['experiment_type'] == 'eval') & (d['predicted_variable'] == 'SBP') & (d['k'] == 1)].head(1)[['predicted_variable','experiment_type','k','MAE_DUMMY_MEAN','MAE_DUMMY_STD']]\n",
    "\n",
    "min_eval_sbp = gbm_min_eval_sbp.set_index(['predicted_variable','experiment_type','k']).join(lgbm_min_eval_sbp.set_index(['predicted_variable','experiment_type','k']), on=['predicted_variable','experiment_type','k'])\n",
    "min_eval_sbp = min_eval_sbp.join(rf_min_eval_sbp.set_index(['predicted_variable','experiment_type','k']), on=['predicted_variable','experiment_type','k'])\n",
    "min_eval_sbp = min_eval_sbp.join(lr_min_eval_sbp.set_index(['predicted_variable','experiment_type','k']), on=['predicted_variable','experiment_type','k'])\n",
    "min_eval_sbp = min_eval_sbp.join(dummy_min_eval_sbp.set_index(['predicted_variable','experiment_type','k']), on=['predicted_variable','experiment_type','k'])\n",
    "display(min_eval_sbp)\n",
    "\n",
    "best_results = pd.concat([min_eval_dbp, min_eval_sbp], axis=0)\n",
    "display(best_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "best_results.to_csv('../../results/'+date+'_best_results_eval.csv', index=True, mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
